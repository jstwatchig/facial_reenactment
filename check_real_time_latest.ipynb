{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import the necessary packages\n",
    "from imutils.video import FileVideoStream\n",
    "from imutils import face_utils\n",
    "import datetime\n",
    "import argparse\n",
    "import imutils\n",
    "import math\n",
    "import time\n",
    "import dlib\n",
    "import cv2\n",
    "import numpy as np\n",
    "import sys\n",
    "import subprocess as sp\n",
    "from sklearn.decomposition import PCA\n",
    "from PIL import Image\n",
    "import csv\n",
    "from os import listdir\n",
    "from scipy.spatial.distance import pdist, squareform\n",
    "import weightedstats as ws\n",
    "import shutil\n",
    "\n",
    "w = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] loading facial landmark predictor...\n"
     ]
    }
   ],
   "source": [
    "# load landmark detector\n",
    "print(\"[INFO] loading facial landmark predictor...\")\n",
    "detector = dlib.get_frontal_face_detector()\n",
    "predictor = dlib.shape_predictor('shape_predictor_68_face_landmarks.dat')\n",
    "fa = face_utils.FaceAligner(predictor, desiredFaceWidth=256)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for testing purpose\n",
    "def lip_detect(frame):\n",
    "        # load the input image, resize it, and convert it to grayscale\n",
    "        clone = np.zeros([256,256,3],dtype=np.uint8)\n",
    "        image = cv2.imread(frame)\n",
    "        image = imutils.resize(image, width=256)\n",
    "        gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "        rects = detector(gray, 1)\n",
    "\n",
    "        # loop over the face detections\n",
    "        for (i, rect) in enumerate(rects):\n",
    "            # determine the facial landmarks for the face region, then\n",
    "            # convert the landmark (x, y)-coordinates to a NumPy array\n",
    "            shape = predictor(gray, rect)\n",
    "            shape = face_utils.shape_to_np(shape)\n",
    "\n",
    "            # loop over the face parts individually\n",
    "            for (name, (i, j)) in face_utils.FACIAL_LANDMARKS_IDXS.items():\n",
    "                # clone the original image so we can draw on it, then\n",
    "                # display the name of the face part on the image\n",
    "                if name == \"mouth\":\n",
    "                    # loop over the subset of facial landmarks, drawing the\n",
    "                    # specific face part\n",
    "                    for (x, y) in shape[i:j]:\n",
    "                        cv2.circle(clone, (x, y), 2, (0, 0, 255), -1)\n",
    "                        cv2.circle(image, (x, y), 2, (0, 0, 255), -1)\n",
    "\n",
    "        return clone, image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to calculate the weighted median \n",
    "def weighted_median(data, midpoint, weights=None):\n",
    "    import numpy as np\n",
    "    if weights is None:\n",
    "        return np.median(np.array(data).flatten())\n",
    "    data, weights = np.array(data).flatten(), np.array(weights).flatten()\n",
    "    if any(weights > 0):\n",
    "        sorted_data, sorted_weights = map(np.array, zip(*sorted(zip(data, weights))))\n",
    "        if any(weights > midpoint):\n",
    "            return (data[weights == np.max(weights)])[0]\n",
    "        cumulative_weight = np.cumsum(sorted_weights)\n",
    "        below_midpoint_index = np.where(cumulative_weight <= midpoint)[0][-1]\n",
    "        if cumulative_weight[below_midpoint_index] - midpoint < sys.float_info.epsilon:\n",
    "            return np.mean(sorted_data[below_midpoint_index:below_midpoint_index+2])\n",
    "    return sorted_data[below_midpoint_index+1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# don't use\n",
    "# function to calculate sigma (to be changed)\n",
    "def calcSigma(S_n, S_N, S_target, n, N):\n",
    "    sigma = 0\n",
    "    temp1 = 0\n",
    "    t = 0\n",
    "    for i in range(1, 1000):\n",
    "        # print(\"for i=\"+str(i/10))\n",
    "        x2 = np.sum(calcWeight(S_N, S_target, N, i/10))\n",
    "        x1 = np.sum(calcWeight(S_n, S_target, n, i/10))\n",
    "        temp = x1 - (0.9*x2)\n",
    "        print(temp)\n",
    "        if t == 0:\n",
    "            sigma = i/10\n",
    "            temp1 = math.fabs(temp)\n",
    "            t = 1\n",
    "        else:\n",
    "            if math.fabs(temp) < temp1:\n",
    "                sigma = i/10\n",
    "                temp1 = math.fabs(temp)\n",
    "    # print('sigma is'+str(sigma))\n",
    "    return sigma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to calculate sigma (to be changed)\n",
    "# to be used\n",
    "def calcSigma(S_n, S_N, S_target, n, N):\n",
    "    left = 1\n",
    "    right = 1000\n",
    "    while left < right:\n",
    "        mid = int(left + (right - left) / 2)\n",
    "        start = np.sum(calcWeight1(S_n, S_target, n, left/10)) - 0.9*np.sum(calcWeight1(S_N, S_target, N, left/10))\n",
    "        end = np.sum(calcWeight1(S_n, S_target, n, right/10)) - 0.9*np.sum(calcWeight1(S_N, S_target, N, right/10))\n",
    "#         print('left '+str(start))\n",
    "#         print('right '+str(end))\n",
    "        if start > end:\n",
    "            right = mid\n",
    "        else:\n",
    "            left = mid+1\n",
    "    return left"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to calculate weight, given sigma (to be changed to include sigma)\n",
    "# legacy\n",
    "def calcWeight(S, S_target, len, sigma):\n",
    "    sqSum=0\n",
    "    # print(S)\n",
    "#     # print(S_target)\n",
    "#     S = S.astype(int)\n",
    "#     S_target = S.astype(int)\n",
    "    global w \n",
    "    w = []\n",
    "    for i in range(len):\n",
    "        sqSum = 0.0\n",
    "        for j in range(25):\n",
    "            sqSum += (S[i, j]-S_target[j])**2\n",
    "            p = sqSum/(2*sigma*sigma)\n",
    "        w = np.append(w, np.exp(-p))\n",
    "    print(w)\n",
    "    return w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to calculate weight, given sigma (to be changed to include sigma)\n",
    "# legacy\n",
    "def calcWeight(S, S_target, len, sigma):\n",
    "    sqSum=0\n",
    "    # print(S)\n",
    "    # print(S_target)\n",
    "    global w \n",
    "    w = []\n",
    "    for i in range(len):\n",
    "        sqSum = 0\n",
    "        for j in range(36):\n",
    "            sqSum += (S[i, j]-S_target[j])^2\n",
    "            p = sqSum/(2*sigma*sigma)\n",
    "        w = np.append(w, np.exp(-p))\n",
    "    # print(w)\n",
    "    return w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to calculate weight, given sigma (to be changed to include sigma)\n",
    "# to be used\n",
    "def calcWeight(S, S_target, len, sigma):\n",
    "    # print(S)\n",
    "    # print(S_target)\n",
    "    const = 2*(sigma**2)\n",
    "    global w \n",
    "    w = []\n",
    "    for i in range(len):\n",
    "        z = (np.linalg.norm(S[i] - S_target))**2\n",
    "        w = np.append(w, np.exp(-z/const))\n",
    "        # print(np.linalg.norm(S[i] - S_target))\n",
    "    # print(w)\n",
    "    return w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to calculate weight, given sigma (to be changed to include sigma)\n",
    "# to be used\n",
    "def calcWeight1(S, S_target, len, sigma):\n",
    "    # print(S)\n",
    "    # print(S_target)\n",
    "    const = 2*(sigma**2)\n",
    "    global w \n",
    "    w = []\n",
    "    for i in range(len):\n",
    "        z = (np.linalg.norm(S[i] - S_target))**2\n",
    "        w = np.append(w, np.exp(-z/const))\n",
    "        # print(z)\n",
    "    # print(w)\n",
    "    return w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# don't use\n",
    "def weigtedMedianPP(img, frame, x, y, n, w, sum_w):\n",
    "    val = cv2.imread(frame)[x][y]\n",
    "    median_pixel = np.zeros(3)\n",
    "    weighted_sum = np.zeros(3)\n",
    "    for i in range(n):\n",
    "        c = cv2.imread(img[i])[x][y]\n",
    "        # val1 = w[i] * (c-val)\n",
    "        # weighted_sum += val1\n",
    "        for j in range(0,3):\n",
    "            a = c[j]\n",
    "            b = val[j]\n",
    "            if a >= b:\n",
    "                median_pixel[j] += w[i]*abs(a-b)\n",
    "            else:\n",
    "                median_pixel[j] += w[i]*abs(b-a)\n",
    "    # print(weighted_sum)\n",
    "    # weighted_sum /= sum_w\n",
    "    # weighted_sum = weighted_sum.astype(int)\n",
    "    # print(str(x)+'-'+str(y)+'-'+'=='+str(weighted_sum))\n",
    "    # print(str(x)+' '+str(y)+' '+'['+str(median_pixel[0]/sum_w)+' '+str(median_pixel[1]/sum_w)+' '+str(median_pixel[2]/sum_w)+']')\n",
    "    return (median_pixel[0]/sum_w, median_pixel[1]/sum_w, median_pixel[2]/sum_w)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "# don't use\n",
    "# to optimize - reduce 3 channels to 1\n",
    "def weigtedMedianPP(img, x, y, n, w):\n",
    "    median_pixel_b = []\n",
    "    median_pixel_g = []\n",
    "    median_pixel_r = []\n",
    "    weighted_sum = np.zeros(3)\n",
    "    for i in range(n):\n",
    "        c = cv2.imread(img[i])[x][y]\n",
    "        median_pixel_b = np.append(median_pixel_b,c[0])\n",
    "        median_pixel_g = np.append(median_pixel_g,c[1])\n",
    "        median_pixel_r = np.append(median_pixel_r,c[2])\n",
    "    a = weighted_median(median_pixel_b, weights = w)\n",
    "    b = weighted_median(median_pixel_g, weights = w)\n",
    "    c = weighted_median(median_pixel_r, weights = w)\n",
    "    return (a, b, c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "# don't use\n",
    "# to optimize - reduce 3 channels to 1\n",
    "def weigtedMedianPP(img, x, y, n, w, weight_sum):\n",
    "    median_pixel_b = []\n",
    "    median_pixel_g = []\n",
    "    median_pixel_r = []\n",
    "    t = 0\n",
    "    for i in range(n):\n",
    "        c = Image.open(img[i])\n",
    "        b, g, r = c.split()\n",
    "        if t == 0:\n",
    "            median_pixel_b = np.append(median_pixel_b, b)\n",
    "            median_pixel_g = np.append(median_pixel_g, g)\n",
    "            median_pixel_r = np.append(median_pixel_r, r)\n",
    "            t = 1\n",
    "        else:\n",
    "            median_pixel_b = np.vstack((median_pixel_b, b))\n",
    "            median_pixel_g = np.vstack((median_pixel_g, g))\n",
    "            median_pixel_r = np.vstack((median_pixel_r, r))            \n",
    "    a = ws.numpy_weighted_median(median_pixel_b, weights = w)\n",
    "    b = ws.numpy_weighted_median(median_pixel_g, weights = w)\n",
    "    c = ws.numpy_weighted_median(median_pixel_r, weights = w)\n",
    "    print(a)\n",
    "    print(b)\n",
    "    print(c)\n",
    "    return (a, b, c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to fetch and store the specific patch of respective frames for mask generation\n",
    "def maskFrames(imgs, centres, N):\n",
    "    new_imgs = []\n",
    "    centres = centres.astype(int)\n",
    "    for i in range(N):\n",
    "        img = cv2.imread(imgs[i])\n",
    "        v = Image.fromarray(img[(centres[i][1]-50):(centres[i][1]+50), (centres[i][0]-50):(centres[i][0]+50)])\n",
    "        b, g, r = v.split()\n",
    "        inter_img = Image.merge(\"RGB\", (r, g, b))\n",
    "        dirs = imgs[i].replace(\"target\",\"intermediate\")\n",
    "        shutil.copyfile(imgs[i], dirs)\n",
    "        val = \"/home/shuvam/Downloads/facial-landmarks/internal/img\"+str(i)+\".jpg\"\n",
    "        inter_img.save(val)\n",
    "        new_img = lip_detect(imgs[i])\n",
    "        cv2.imwrite(\"/home/shuvam/Downloads/facial-landmarks/space/img\"+str(i)+\".jpg\", new_img)\n",
    "        new_imgs = np.append(new_imgs, val)\n",
    "    return new_imgs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to calculate weighted median\n",
    "def weightedMedian(S_all, S_target, target_frame, S_centres, S_centres_n, frames, target_centre, S_vec, S_vec_n, n, N, weights):\n",
    "    x_num = 100\n",
    "    y_num = 100\n",
    "    \n",
    "    weight_sum = 0.5*np.sum(weights)\n",
    "    centre_x = int(target_centre[0] - (y_num/2))\n",
    "    centre_y = int(target_centre[1] - (x_num/2))\n",
    "    masked_images_n = maskFrames(S_vec_n, S_centres_n, n)\n",
    "    im_res = np.zeros((x_num, y_num, 3))\n",
    "    S_target_new = cv2.imread(target_frame)\n",
    "    S_int = np.zeros((100, 100, 3))\n",
    "    \n",
    "    b = []\n",
    "    g = []\n",
    "    r = []\n",
    "#     g = [[[] for x in range(x_num)] for y in range(y_num)]\n",
    "#     r = [[[] for x in range(x_num)] for y in range(y_num)]\n",
    "    t = 0\n",
    "    b1 = []\n",
    "    g1 = []\n",
    "    r1 = []\n",
    "    for x in range(n):\n",
    "        img = Image.open(masked_images_n[x])\n",
    "        B, G, R = img.split()\n",
    "        B = np.asarray(B)\n",
    "        G = np.asarray(G)\n",
    "        R = np.asarray(R)\n",
    "        if t == 0:\n",
    "            b = np.append(b, np.reshape(B, (np.product(B.shape),)))\n",
    "            g = np.append(g, np.reshape(G, (np.product(G.shape),)))\n",
    "            r = np.append(r, np.reshape(R, (np.product(R.shape),)))\n",
    "            t = 1\n",
    "        else:\n",
    "            b = np.vstack((b, np.reshape(B, (np.product(B.shape),))))\n",
    "            g = np.vstack((g, np.reshape(G, (np.product(G.shape),))))\n",
    "            r = np.vstack((r, np.reshape(R, (np.product(R.shape),))))\n",
    "#                 g[i][j] = np.append(g[i][j], G)\n",
    "#                 r[i][j] = np.append(r[i][j], R)\n",
    "    \n",
    "#     for i in range(x_num):\n",
    "#         for j in range(y_num):\n",
    "# #             S_target_new[int(centre_y+i)][int(centre_x+j)] = (weighted_median(median_pixel_b, weight_sum, weights = w), weighted_median(median_pixel_g, weight_sum, weights = w), weighted_median(median_pixel_r, weight_sum, weights = w))  \n",
    "#             t = weighted_median(b[i][j], weight_sum, weights = w)\n",
    "#             S_int[x][y] = lst\n",
    "   # print(w)\n",
    "    for i in range (x_num*y_num):\n",
    "        # print(i)\n",
    "        b1 = np.append(b1, weighted_median(b[:,i], weight_sum, weights = w))\n",
    "        g1 = np.append(g1, weighted_median(g[:,i], weight_sum, weights = w))\n",
    "        r1 = np.append(r1, weighted_median(r[:,i], weight_sum, weights = w))\n",
    "    t = 0\n",
    "    for i in range(x_num):\n",
    "        for j in range(y_num):\n",
    "            z = (r1[t], g1[t], b1[t])\n",
    "            # S_target_new[int(centre_y+i)][int(centre_x+j)] = z\n",
    "            S_int[i][j] = z\n",
    "            t += 1\n",
    "#     print(np.shape(b[:,1]))\n",
    "    S_new = combine_frames(S_target_new, S_int, centre_x, centre_y)\n",
    "    return S_new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function for applying patch on target frame\n",
    "def combine_frames(S_target, S_int, centre_x, centre_y):\n",
    "    max = 3000\n",
    "    x = 0\n",
    "    y = 0\n",
    "    row = np.shape(S_int)[0]\n",
    "    col = np.shape(S_int)[1]\n",
    "    for i in range((centre_y-10),(centre_y+10)):\n",
    "        for j in range((centre_x-10),(centre_x+10)):\n",
    "            val = np.linalg.norm(S_target[i][j:j+col]-S_int[0])\n",
    "            if(val < max):\n",
    "                max = val\n",
    "                x = i\n",
    "                y = j\n",
    "    S_target[x:x+row, y:y+col] = S_int\n",
    "    return S_target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# don't use\n",
    "def weightedMedian(S_all, S_target, target_frame, S_centres, S_centres_n, target_centre, S_vec, S_vec_n, n, N, weights):\n",
    "    x_num = 100\n",
    "    y_num = 100\n",
    "    # print(weights)\n",
    "    weight_sum = np.sum(weights)\n",
    "    centre_x = target_centre[0] - (y_num/2)\n",
    "    centre_y = target_centre[1] - (x_num/2)\n",
    "    masked_images_n = maskFrames(S_vec_n, S_centres_n, n)\n",
    "    im_res = np.zeros((x_num, y_num, 3))\n",
    "    S_target_new = cv2.imread(target_frame)\n",
    "    S_int = np.zeros((100, 100, 3))\n",
    "    # print(S_centres_n[0])\n",
    "    # print(S_centres_n[1])\n",
    "    # print(target_centre[0])\n",
    "    # print(target_centre[1])\n",
    "    for x in range(x_num):\n",
    "        for y in range(y_num):\n",
    "            lst = weigtedMedianPP(masked_images_n, x, y, n, weights)\n",
    "            # S_target_new[int(centre_y+x)][int(centre_x+y)] = lst\n",
    "            S_int[x][y] = lst\n",
    "    return S_target_new, S_int.astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# used for generating PCA from video\n",
    "def find_PCA(video_link, folder):\n",
    "    vs = FileVideoStream(video_link).start()\n",
    "    time.sleep(2.0)\n",
    "    frameNo = 1\n",
    "    t = 0\n",
    "    imgs_rslt = []\n",
    "    centres = []\n",
    "    frame_list = []\n",
    "    length = int(cv2.VideoCapture(video_link).get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "\n",
    "    # loop over the frames from the video stream\n",
    "    while True:\n",
    "        # grab the frame from the threaded video stream, resize it to\n",
    "        # have a maximum width of 600 pixels, and convert it to\n",
    "        # grayscale\n",
    "        \n",
    "        frame = vs.read()\n",
    "        # frame = np.rot90(frame)\n",
    "        \n",
    "        frame = imutils.resize(frame, width=600)\n",
    "        gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "        # detect faces in the grayscale frame\n",
    "        rects = detector(gray, 0)\n",
    "        \n",
    "        # loop over the face detections\n",
    "        for rect in rects:\n",
    "            # determine the facial landmarks for the face region, then\n",
    "            # convert the facial landmark (x, y)-coordinates to a NumPy\n",
    "            # array\n",
    "            faceAligned = fa.align(frame, gray, rect)\n",
    "            dirs = folder + str(999+frameNo) + \".jpg\"\n",
    "            cv2.imwrite(dirs, faceAligned)\n",
    "            rectan = dlib.rectangle(0, 0, 256, 256)\n",
    "            grays = cv2.cvtColor(faceAligned, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "            shape = predictor(grays, rectan)\n",
    "            shape = face_utils.shape_to_np(shape)\n",
    "            \n",
    "            # reduced shapes\n",
    "#             shapes = shape[60:68]\n",
    "            \n",
    "            \n",
    "            # changed implementation\n",
    "            shapes = shape[48:68]\n",
    "            angle = calcAngle(shapes, frameNo)\n",
    "            \n",
    "            # original implementation\n",
    "#             shapes = np.concatenate([shape[48:61], shape[62:65]])\n",
    "#             shapes = np.concatenate([shapes, shape[66:69]])\n",
    "            \n",
    "            \n",
    "            imgs = np.reshape(shapes, (np.product(shapes.shape),))\n",
    "            \n",
    "            if t == 0:\n",
    "                centres = np.append(centres, np.sum(shapes, axis=0))\n",
    "                imgs_rslt = np.append(imgs_rslt,imgs)\n",
    "                t = 1\n",
    "\n",
    "            else:\n",
    "                centres = np.vstack((centres, np.sum(shapes, axis=0)))\n",
    "                imgs_rslt = np.vstack((imgs_rslt,imgs))\n",
    "            \n",
    "            frame_list = np.append(frame_list, dirs)\n",
    "\n",
    "        # increment frame count\n",
    "        if frameNo < length:\n",
    "            frameNo += 1\n",
    "        else:\n",
    "            vs.stop()\n",
    "            break\n",
    "\n",
    "    imgs_rslt = imgs_rslt.astype(int)\n",
    "    centres = (centres/[20, 20]).astype(int)\n",
    "    # print(centres)\n",
    "    pca = PCA(n_components=20)\n",
    "    img_pca = pca.fit_transform(imgs_rslt)\n",
    "    print(\"Done here...\")\n",
    "    return imgs_rslt, img_pca, frame_list, length, centres"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# modified image loading\n",
    "# generates PCA from saved images\n",
    "def find_PCA1(folder):\n",
    "    time.sleep(2.0)\n",
    "    frameNo = 1000\n",
    "    t = 0\n",
    "    imgs_rslt = []\n",
    "    centres = []\n",
    "    angles = []\n",
    "    frame_list = []\n",
    "    imagesList = sorted(listdir(folder))\n",
    "    length = len(imagesList)\n",
    "\n",
    "    # loop over the frames from the video stream\n",
    "    for image in imagesList:\n",
    "        # grab the frame from the threaded video stream, resize it to\n",
    "        # have a maximum width of 600 pixels, and convert it to\n",
    "        # grayscale\n",
    "        \n",
    "        frame = cv2.imread(folder + image)\n",
    "        \n",
    "        if frameNo >= 1000:\n",
    "            frame = imutils.resize(frame, width=600)\n",
    "            gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "            # detect faces in the grayscale frame\n",
    "            rects = detector(gray, 0)\n",
    "\n",
    "            # loop over the face detections\n",
    "            for rect in rects:\n",
    "                # determine the facial landmarks for the face region, then\n",
    "                # convert the facial landmark (x, y)-coordinates to a NumPy\n",
    "                # array\n",
    "                faceAligned = fa.align(frame, gray, rect)\n",
    "                dirs = folder + image\n",
    "                rectan = dlib.rectangle(0, 0, 256, 256)\n",
    "                grays = cv2.cvtColor(faceAligned, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "                shape = predictor(grays, rectan)\n",
    "                shape = face_utils.shape_to_np(shape)\n",
    "                #print('for frame'+str(frameNo))\n",
    "            # reduced shapes\n",
    "                shapes = shape[48:68]\n",
    "                angle = calcAngle(shapes, frameNo)\n",
    "            \n",
    "            # changed implementation\n",
    "#                shapes = shape[48:68]\n",
    "            \n",
    "            # original implementation\n",
    "#             shapes = np.concatenate([shape[48:61], shape[62:65]])\n",
    "#             shapes = np.concatenate([shapes, shape[66:69]])\n",
    "            \n",
    "            \n",
    "                imgs = np.reshape(shapes, (np.product(shapes.shape),))\n",
    "\n",
    "                if t == 0:\n",
    "                    centres = np.append(centres, np.sum(shapes, axis=0))\n",
    "                    imgs_rslt = np.append(imgs_rslt,imgs)\n",
    "                    angles = np.append(angles,angle)\n",
    "                    t = 1\n",
    "\n",
    "                else:\n",
    "                    centres = np.vstack((centres, np.sum(shapes, axis=0)))\n",
    "                    imgs_rslt = np.vstack((imgs_rslt,imgs))\n",
    "                    angles = np.vstack((angles,angle))\n",
    "\n",
    "                frame_list = np.append(frame_list, dirs)\n",
    "\n",
    "        # increment frame count\n",
    "        frameNo += 1\n",
    "        if frameNo == 2500:\n",
    "            break\n",
    "\n",
    "    imgs_rslt = imgs_rslt.astype(int)\n",
    "    centres = (centres/[20, 20]).astype(int)\n",
    "    # print(centres)\n",
    "    pca = PCA(n_components=16)\n",
    "    img_pca = pca.fit_transform(imgs_rslt)\n",
    "    print(\"Done here...\")\n",
    "    return imgs_rslt, img_pca, frame_list, length, centres, angles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test generated patch\n",
    "# don't use\n",
    "def find_PCA(video_link, folder):\n",
    "    vs = FileVideoStream(video_link).start()\n",
    "    time.sleep(2.0)\n",
    "    frameNo = 1\n",
    "    t = 0\n",
    "    imgs_rslt = []\n",
    "    centres = []\n",
    "    frame_list = []\n",
    "    length = int(cv2.VideoCapture(video_link).get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "\n",
    "    # loop over the frames from the video stream\n",
    "    while True:\n",
    "        # grab the frame from the threaded video stream, resize it to\n",
    "        # have a maximum width of 600 pixels, and convert it to\n",
    "        # grayscale\n",
    "        frame = vs.read()\n",
    "        frame = imutils.resize(frame, width=600)\n",
    "        gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "        # detect faces in the grayscale frame\n",
    "        rects = detector(gray, 0)\n",
    "        \n",
    "        # loop over the face detections\n",
    "        for rect in rects:\n",
    "            # determine the facial landmarks for the face region, then\n",
    "            # convert the facial landmark (x, y)-coordinates to a NumPy\n",
    "            # array\n",
    "            # faceAligned = fa.align(frame, gray, rect)\n",
    "            \n",
    "            (x, y, w, h) = face_utils.rect_to_bb(rect)\n",
    "            print(x)\n",
    "            print(x+w)\n",
    "            print(y)\n",
    "            print(h+y)\n",
    "            print('')\n",
    "            frame = frame[y:y+h, x:x+w]\n",
    "            print(np.shape(frame))\n",
    "            \n",
    "            dirs = folder + str(frameNo) + \".jpg\"\n",
    "            cv2.imwrite(dirs, frame)\n",
    "            \n",
    "            \n",
    "            rectan = dlib.rectangle(0, 0, 256, 256)\n",
    "            grays = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "            shape = predictor(grays, rect)\n",
    "            shape = face_utils.shape_to_np(shape)\n",
    "            \n",
    "            # reduced shapes\n",
    "#             shapes = shape[60:68]\n",
    "            \n",
    "            \n",
    "            # changed implementation\n",
    "            shapes = shape[48:68]\n",
    "            \n",
    "            # original implementation\n",
    "#             shapes = np.concatenate([shape[48:61], shape[62:65]])\n",
    "#             shapes = np.concatenate([shapes, shape[66:69]])\n",
    "            \n",
    "            \n",
    "            imgs = np.reshape(shapes, (np.product(shapes.shape),))\n",
    "            \n",
    "            if t == 0:\n",
    "                centres = np.append(centres, np.sum(shapes, axis=0))\n",
    "                imgs_rslt = np.append(imgs_rslt,imgs)\n",
    "                t = 1\n",
    "\n",
    "            else:\n",
    "                centres = np.vstack((centres, np.sum(shapes, axis=0)))\n",
    "                imgs_rslt = np.vstack((imgs_rslt,imgs))\n",
    "\n",
    "        # increment frame count\n",
    "        frame_list = np.append(frame_list, dirs)\n",
    "        if frameNo < length:\n",
    "            frameNo += 1\n",
    "        else:\n",
    "            vs.stop()\n",
    "            break\n",
    "\n",
    "    imgs_rslt = imgs_rslt.astype(int)\n",
    "    centres = (centres/[20, 20]).astype(int)\n",
    "    # print(centres)\n",
    "    pca = PCA(n_components=20)\n",
    "    img_pca = pca.fit_transform(imgs_rslt)\n",
    "    return imgs_rslt, img_pca, frame_list, length, centres"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# proto func to calc similarity based on angles between landmarks\n",
    "def calcAngle(shapes, frameNo):\n",
    "    refPoint1 = shapes[0]\n",
    "    refPoint2 = shapes[6]\n",
    "    shape = np.concatenate([shapes[1:6], shapes[7:]])\n",
    "    result = []\n",
    "    line1 = refPoint1 - refPoint2\n",
    "    j = 0\n",
    "    for i in shape:\n",
    "        line2 = refPoint1 - i\n",
    "        cosine_angle = np.dot(line1, line2) / (np.linalg.norm(line1) * np.linalg.norm(line2))\n",
    "        angle = np.arccos(cosine_angle)\n",
    "        # print(str(frameNo)+' '+str(j)+' '+str(angle)+' '+str(cosine_angle)+' '+str(line1)+' '+str(line2))\n",
    "        result = np.append(result, np.degrees(angle))\n",
    "        j += 1\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# func to calc l2 similarity \n",
    "def similarity(src_pca, tgt_pca, len):\n",
    "    dist = []\n",
    "    # print(len)\n",
    "    for i in range(len):\n",
    "        if i == 0:\n",
    "            #print(\"here\")\n",
    "            dist = np.append(dist, [i+1, np.linalg.norm(src_pca[i] - tgt_pca)])\n",
    "        else:\n",
    "            dist = np.vstack((dist, [i+1, np.linalg.norm(src_pca[i] - tgt_pca)]))\n",
    "    #print(dist)\n",
    "    dist = dist[dist[:,1].argsort()]\n",
    "    return dist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done here...\n",
      "Done here...\n"
     ]
    }
   ],
   "source": [
    "# pre-processing\n",
    "\n",
    "#sources_vec, sources_pca, sources_frame, sources_len, sources_centre, sources_angles = find_PCA(\"aud.mp4\",\"/home/shuvam/Downloads/facial-landmarks/source/\")\n",
    "source_vec, source_pca, source_frame, source_len, source_centre, source_angles = find_PCA1(\"/home/shuvam/Downloads/facial-landmarks/source/\")\n",
    "#source_vec, source_pca, source_frame, source_len, source_centre, source_angles = find_PCA1(\"/home/shuvam/Downloads/facial-landmarks/source/\")\n",
    "target_vec, target_pca, target_frame, target_len, target_centre, target_angles = find_PCA1(\"/home/shuvam/Downloads/facial-landmarks/target/\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Working on frame 0\n",
      "4\n",
      "Done\n",
      "Elapsed time - 4.289734363555908\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# generate frames\n",
    "n = 30\n",
    "target_len = len(target_vec)\n",
    "source_len = len(source_vec)\n",
    "for i in range(0,1):\n",
    "    start_time = time.time()\n",
    "    y = []\n",
    "    centres = []\n",
    "    rslt = similarity(target_angles, source_angles[i], target_len)\n",
    "    frames = []\n",
    "    rslt1 = rslt\n",
    "    rslt = rslt[:n]\n",
    "    t = 0\n",
    "    # print(source_frame)\n",
    "    new_imgn = lip_detect(source_frame[i])\n",
    "    cv2.imwrite(\"/home/shuvam/Downloads/facial-landmarks/space/src_img.jpg\", new_imgn)\n",
    "    for z in rslt[:,0].astype(int):\n",
    "        if t == 0:\n",
    "            y = np.append(y, target_vec[z-1])\n",
    "            centres = np.append(centres, target_centre[z-1])\n",
    "            frames = np.append(frames, target_frame[z-1])\n",
    "            t = 1\n",
    "        else:\n",
    "            y = np.vstack((y, target_vec[z-1]))\n",
    "            centres = np.vstack((centres, target_centre[z-1]))\n",
    "            frames = np.append(frames, target_frame[z-1])\n",
    "    y = y.astype(int)\n",
    "    print(\"Working on frame \"+str(i))\n",
    "    sigma = calcSigma(y, target_vec, source_vec[i], n, target_len)\n",
    "    # sigma = 15\n",
    "    print(sigma)\n",
    "    weight = calcWeight(y, source_vec[i], n, sigma)\n",
    "    # print(weight)\n",
    "    gen_img = weightedMedian(source_vec, target_vec[i], target_frame[i], source_centre, centres, frames, target_centre[i], source_frame, frames, n, target_len, weight)\n",
    "    gen_img = Image.fromarray(gen_img)\n",
    "    b, g, r = gen_img.split()\n",
    "    gen_img = Image.merge(\"RGB\", (r, g, b))\n",
    "    gen_img.save(\"/home/shuvam/Downloads/facial-landmarks/inter/img\"+('0'*(len(str(target_len))-len(str(i))))+str(i)+\".jpg\")\n",
    "    elapsed_time = time.time() - start_time\n",
    "    print(\"Done\")\n",
    "    print(\"Elapsed time - \" + str(elapsed_time)+'\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# test - don't use\n",
    "\n",
    "#source_vec1, source_pca1, source_frame1, source_len1, source_centre1, source_angles1 = find_PCA(\"cut123.mp4\",\"/home/shuvam/Downloads/facial-landmarks/source1/\")\n",
    "#source_vec2, source_pca2, source_frame2, source_len2, source_centre2, source_angles2 = find_PCA(\"fun123.mp4\",\"/home/shuvam/Downloads/facial-landmarks/source2/\")\n",
    "#source_vec3, source_pca3, source_frame3, source_len3, source_centre3, source_angles3 = find_PCA(\"output123.mp4\",\"/home/shuvam/Downloads/facial-landmarks/source3/\")\n",
    "# source_vec1, source_pca1, source_frame1, source_len1, source_centre1, source_angles1 = find_PCA1(\"/home/shuvam/Downloads/facial-landmarks/source1/\")\n",
    "# source_vec2, source_pca2, source_frame2, source_len2, source_centre2, source_angles2 = find_PCA1(\"/home/shuvam/Downloads/facial-landmarks/source2/\")\n",
    "# source_vec3, source_pca3, source_frame3, source_len3, source_centre3, source_angles3 = find_PCA1(\"/home/shuvam/Downloads/facial-landmarks/source3/\")\n",
    "for i in range(source_len1):\n",
    "    new_imgn, new_imgx = lip_detect(source_frame1[i])\n",
    "    cv2.imwrite(\"/home/shuvam/Downloads/facial-landmarks/space(cut123)/src_img\"+str(1000+i)+\".jpg\", new_imgn)\n",
    "    cv2.imwrite(\"/home/shuvam/Downloads/facial-landmarks/space_x(cut123)/src_img\"+str(1000+i)+\".jpg\", new_imgx)\n",
    "for i in range(source_len2):\n",
    "    new_imgn, new_imgx = lip_detect(source_frame2[i])\n",
    "    cv2.imwrite(\"/home/shuvam/Downloads/facial-landmarks/space(fun123)/src_img\"+str(1000+i)+\".jpg\", new_imgn)\n",
    "    cv2.imwrite(\"/home/shuvam/Downloads/facial-landmarks/space_x(fun123)/src_img\"+str(1000+i)+\".jpg\", new_imgx)\n",
    "for i in range(source_len3):\n",
    "    new_imgn, new_imgx = lip_detect(source_frame3[i])\n",
    "    cv2.imwrite(\"/home/shuvam/Downloads/facial-landmarks/space(output123)/src_img\"+str(1000+i)+\".jpg\", new_imgn)\n",
    "    cv2.imwrite(\"/home/shuvam/Downloads/facial-landmarks/space_x(output123)/src_img\"+str(1000+i)+\".jpg\", new_imgx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done here...\n"
     ]
    }
   ],
   "source": [
    "# test - don't use\n",
    "\n",
    "#source_vec, source_pca, source_frame, source_len, source_centre, source_angles = find_PCA(\"cut123.mp4\",\"/home/shuvam/Downloads/facial-landmarks/source/\")\n",
    "#source_vec, source_pca, source_frame, source_len, source_centre, source_angles = find_PCA1(\"/home/shuvam/Downloads/facial-landmarks/source/\")\n",
    "for i in range(source_len):\n",
    "    new_imgn, new_imgx = lip_detect(source_frame[i])\n",
    "    cv2.imwrite(\"/home/shuvam/Downloads/facial-landmarks/space/src_img\"+str(1000+i)+\".jpg\", new_imgn)\n",
    "    cv2.imwrite(\"/home/shuvam/Downloads/facial-landmarks/space_x/src_img\"+str(1000+i)+\".jpg\", new_imgx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1500, 2)\n",
      "1500\n",
      "/home/shuvam/Downloads/facial-landmarks/source/1075.jpg\n",
      "[[  9.67000000e+02   5.10171821e-01]\n",
      " [  2.90000000e+01   7.88856367e-01]\n",
      " [  9.16000000e+02   9.77034278e-01]\n",
      " ..., \n",
      " [  1.96000000e+02              nan]\n",
      " [  2.25000000e+02              nan]\n",
      " [  2.26000000e+02              nan]]\n",
      "[[  1.           0.51017182]\n",
      " [  2.          38.29837635]]\n"
     ]
    }
   ],
   "source": [
    "# test - don't use\n",
    "\n",
    "print(np.shape(rslt1))\n",
    "print(target_len)\n",
    "print(source_frame[75])\n",
    "print(similarity(target_angles, source_angles[75], target_len))\n",
    "print(similarity(target_angles[966:969], source_angles[75], 2))\n",
    "# print(target_frame[0:5])\n",
    "# print(frames[0:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 4473.            10.95445115]\n",
      " [ 3727.            13.07669683]\n",
      " [ 4409.            13.22875656]\n",
      " [ 4408.            14.03566885]\n",
      " [ 3720.            15.03329638]\n",
      " [ 3700.            15.06651917]\n",
      " [ 3726.            15.13274595]\n",
      " [ 3823.            15.13274595]\n",
      " [ 3830.            15.39480432]\n",
      " [ 3725.            15.49193338]\n",
      " [ 2703.            15.71623365]\n",
      " [ 4472.            15.8113883 ]\n",
      " [ 3701.            15.87450787]\n",
      " [ 3721.            16.0623784 ]\n",
      " [ 3931.            16.2788206 ]\n",
      " [ 3744.            16.2788206 ]\n",
      " [ 2701.            16.55294536]\n",
      " [ 3719.            16.64331698]\n",
      " [ 3724.            16.70329309]\n",
      " [ 2704.            16.73320053]\n",
      " [ 2700.            16.73320053]\n",
      " [ 3557.            16.76305461]\n",
      " [ 3738.            16.79285562]\n",
      " [ 4410.            16.82260384]\n",
      " [ 2702.            16.85229955]\n",
      " [ 3745.            16.91153453]\n",
      " [ 4412.            17.        ]\n",
      " [ 3829.            17.11724277]\n",
      " [ 4414.            17.20465053]\n",
      " [  415.            17.29161647]\n",
      " [ 3558.            17.40689519]\n",
      " [ 4415.            17.49285568]\n",
      " [ 4407.            17.52141547]\n",
      " [ 2698.            17.57839583]\n",
      " [ 3822.            17.66352173]\n",
      " [ 4406.            17.94435844]\n",
      " [ 4405.            17.94435844]\n",
      " [ 4411.            17.97220076]\n",
      " [ 3737.            18.08314132]\n",
      " [ 3722.            18.11077028]\n",
      " [ 3556.            18.11077028]\n",
      " [ 3572.            18.35755975]\n",
      " [ 3743.            18.38477631]\n",
      " [ 3824.            18.49324201]\n",
      " [ 2681.            18.54723699]\n",
      " [ 1256.            18.54723699]\n",
      " [ 4413.            18.60107524]\n",
      " [ 4474.            18.86796226]\n",
      " [ 3730.            18.92088793]\n",
      " [  238.            18.92088793]]\n",
      "left 0.0\n",
      "right -3705.03307557\n",
      "left 0.0\n",
      "right -2781.88294126\n",
      "left 0.0\n",
      "right -1021.38349646\n",
      "left 0.0\n",
      "right -52.6194420349\n",
      "left 0.0\n",
      "right -0.0415239090607\n",
      "left 0.0\n",
      "right 3.21606883688e-07\n",
      "left 2.09343014532e-21\n",
      "right 3.21606883688e-07\n",
      "left 1.0859777969e-10\n",
      "right 3.21606883688e-07\n",
      "left 2.25895981239e-08\n",
      "right 3.21606883688e-07\n",
      "left 1.46553747663e-07\n",
      "right 3.21606883688e-07\n",
      "32\n"
     ]
    }
   ],
   "source": [
    "# test - don't use\n",
    "\n",
    "n = 50\n",
    "target_len = len(target_vec)\n",
    "y = []\n",
    "rslt = similarity(target_vec, source_vec[108], target_len)\n",
    "rslt = rslt[:n]\n",
    "print(rslt)\n",
    "t = 0\n",
    "for z in rslt[:,0].astype(int):\n",
    "    if t == 0:\n",
    "        y = np.append(y, target_vec[z-1])\n",
    "        t = 1\n",
    "    else:\n",
    "        y = np.vstack((y, target_vec[z-1]))\n",
    "y = y.astype(int)\n",
    "sigma = calcSigma(y, target_vec, source_vec[107], n, target_len)\n",
    "print(sigma)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(150, 25)\n",
      "[  27.36274246   27.36274246   27.36274246   27.36274246   27.36274246\n",
      "   27.36274246   27.36274246   27.36274246   27.36274246   27.36274246\n",
      "   27.36274246   27.36274246   27.36274246   27.36274246   27.36274246\n",
      "   27.36274246   27.36274246   27.36274246   27.36274246   27.36274246\n",
      "   27.36274246   27.36274246   27.36274246   27.36274246   27.36274246\n",
      "   27.36274246   56.65156229   87.33453298   87.33453298   87.33453298\n",
      "   87.33453298   87.33453298   56.65156229   56.65156229   56.65156229\n",
      "   56.65156229   56.65156229   56.65156229   27.36274246   27.36274246\n",
      "   27.36274246   56.65156229   27.36274246   39.41564883   39.41564883\n",
      "   59.42275555   59.42275555   59.42275555   59.42275555   39.41564883\n",
      "   39.41564883   39.41564883   59.42275555   59.42275555   59.42275555\n",
      "   59.42275555   59.42275555   59.42275555  106.75652494   59.42275555\n",
      "   59.42275555   59.42275555   59.42275555  106.75652494  106.75652494\n",
      "  106.75652494  106.75652494  106.75652494  106.75652494  106.75652494\n",
      "  106.75652494  106.75652494  106.75652494  106.75652494  106.75652494\n",
      "  106.75652494  106.75652494  106.75652494  106.75652494  106.75652494\n",
      "  106.75652494  106.75652494  102.5329105   106.75652494  106.75652494\n",
      "  106.75652494  106.75652494  106.75652494   57.58662766   57.58662766\n",
      "  106.75652494   57.58662766   57.58662766   57.58662766   57.58662766\n",
      "   57.58662766   57.58662766   59.42275555   57.58662766   57.58662766\n",
      "   57.58662766   57.58662766   57.58662766   57.58662766   50.11333143\n",
      "   50.11333143   50.11333143   57.58662766   57.58662766   50.11333143\n",
      "   50.11333143   50.11333143   50.11333143   50.11333143   50.11333143\n",
      "   50.11333143   50.11333143   50.11333143   29.40925567   50.11333143\n",
      "   50.11333143   50.11333143   50.11333143   50.11333143   50.11333143\n",
      "   50.11333143   50.11333143   59.42275555   59.42275555   59.42275555\n",
      "   50.11333143   50.11333143   50.11333143   50.11333143   59.42275555\n",
      "   59.42275555   59.42275555   59.42275555   59.42275555   59.42275555\n",
      "   59.42275555   59.42275555   59.42275555   59.42275555   59.42275555\n",
      "   59.42275555   59.42275555   59.42275555   57.58662766   57.58662766]\n",
      "[[  32.           50.91168825]\n",
      " [  28.           50.91168825]\n",
      " [  29.           50.91168825]\n",
      " [  30.           50.91168825]\n",
      " [  31.           50.91168825]\n",
      " [  27.           70.5478561 ]\n",
      " [  33.           70.5478561 ]\n",
      " [  34.           70.5478561 ]\n",
      " [  42.           70.5478561 ]\n",
      " [  36.           70.5478561 ]\n",
      " [  37.           70.5478561 ]\n",
      " [  38.           70.5478561 ]\n",
      " [  35.           70.5478561 ]\n",
      " [  51.           86.61408661]\n",
      " [  50.           86.61408661]\n",
      " [  45.           86.61408661]\n",
      " [  52.           86.61408661]\n",
      " [  44.           86.61408661]\n",
      " [  65.           97.5807358 ]\n",
      " [  59.           97.5807358 ]\n",
      " [  64.           97.5807358 ]\n",
      " [  75.           97.5807358 ]\n",
      " [  68.           97.5807358 ]\n",
      " [  88.           97.5807358 ]\n",
      " [  87.           97.5807358 ]\n",
      " [  86.           97.5807358 ]\n",
      " [  85.           97.5807358 ]\n",
      " [  84.           97.5807358 ]\n",
      " [  82.           97.5807358 ]\n",
      " [  81.           97.5807358 ]\n",
      " [  80.           97.5807358 ]\n",
      " [  67.           97.5807358 ]\n",
      " [  79.           97.5807358 ]\n",
      " [  77.           97.5807358 ]\n",
      " [  76.           97.5807358 ]\n",
      " [  74.           97.5807358 ]\n",
      " [  73.           97.5807358 ]\n",
      " [  72.           97.5807358 ]\n",
      " [  71.           97.5807358 ]\n",
      " [  70.           97.5807358 ]\n",
      " [  69.           97.5807358 ]\n",
      " [  78.           97.5807358 ]\n",
      " [  66.           97.5807358 ]\n",
      " [  91.           97.5807358 ]\n",
      " [  46.          110.06361797]\n",
      " [ 137.          110.06361797]\n",
      " [ 140.          110.06361797]\n",
      " [ 136.          110.06361797]\n",
      " [ 135.          110.06361797]\n",
      " [ 130.          110.06361797]\n",
      " [ 129.          110.06361797]\n",
      " [ 128.          110.06361797]\n",
      " [ 141.          110.06361797]\n",
      " [ 142.          110.06361797]\n",
      " [ 143.          110.06361797]\n",
      " [ 144.          110.06361797]\n",
      " [ 145.          110.06361797]\n",
      " [  63.          110.06361797]\n",
      " [  62.          110.06361797]\n",
      " [ 138.          110.06361797]\n",
      " [  61.          110.06361797]\n",
      " [ 146.          110.06361797]\n",
      " [  47.          110.06361797]\n",
      " [  48.          110.06361797]\n",
      " [  49.          110.06361797]\n",
      " [ 148.          110.06361797]\n",
      " [  98.          110.06361797]\n",
      " [  60.          110.06361797]\n",
      " [ 147.          110.06361797]\n",
      " [  54.          110.06361797]\n",
      " [  55.          110.06361797]\n",
      " [  56.          110.06361797]\n",
      " [  57.          110.06361797]\n",
      " [  58.          110.06361797]\n",
      " [  53.          110.06361797]\n",
      " [ 139.          110.06361797]\n",
      " [  83.          115.19114549]\n",
      " [  93.          132.49150916]\n",
      " [  96.          132.49150916]\n",
      " [ 109.          132.49150916]\n",
      " [  95.          132.49150916]\n",
      " [ 104.          132.49150916]\n",
      " [ 103.          132.49150916]\n",
      " [ 102.          132.49150916]\n",
      " [ 101.          132.49150916]\n",
      " [ 100.          132.49150916]\n",
      " [  99.          132.49150916]\n",
      " [  97.          132.49150916]\n",
      " [  92.          132.49150916]\n",
      " [  94.          132.49150916]\n",
      " [ 108.          132.49150916]\n",
      " [ 150.          132.49150916]\n",
      " [  89.          132.49150916]\n",
      " [  90.          132.49150916]\n",
      " [ 149.          132.49150916]\n",
      " [   2.          137.46999673]\n",
      " [  17.          137.46999673]\n",
      " [  16.          137.46999673]\n",
      " [  15.          137.46999673]\n",
      " [  14.          137.46999673]\n",
      " [  13.          137.46999673]\n",
      " [  12.          137.46999673]\n",
      " [  11.          137.46999673]\n",
      " [  10.          137.46999673]\n",
      " [   8.          137.46999673]\n",
      " [   7.          137.46999673]\n",
      " [   6.          137.46999673]\n",
      " [   5.          137.46999673]\n",
      " [   4.          137.46999673]\n",
      " [   3.          137.46999673]\n",
      " [  18.          137.46999673]\n",
      " [   9.          137.46999673]\n",
      " [   1.          137.46999673]\n",
      " [  23.          137.46999673]\n",
      " [  43.          137.46999673]\n",
      " [  41.          137.46999673]\n",
      " [  40.          137.46999673]\n",
      " [  39.          137.46999673]\n",
      " [  26.          137.46999673]\n",
      " [  25.          137.46999673]\n",
      " [  24.          137.46999673]\n",
      " [  19.          137.46999673]\n",
      " [  22.          137.46999673]\n",
      " [  21.          137.46999673]\n",
      " [  20.          137.46999673]\n",
      " [ 119.          138.67948659]\n",
      " [ 107.          170.14699527]\n",
      " [ 114.          170.14699527]\n",
      " [ 105.          170.14699527]\n",
      " [ 134.          170.14699527]\n",
      " [ 106.          170.14699527]\n",
      " [ 133.          170.14699527]\n",
      " [ 132.          170.14699527]\n",
      " [ 131.          170.14699527]\n",
      " [ 115.          170.14699527]\n",
      " [ 116.          170.14699527]\n",
      " [ 117.          170.14699527]\n",
      " [ 118.          170.14699527]\n",
      " [ 120.          170.14699527]\n",
      " [ 112.          170.14699527]\n",
      " [ 113.          170.14699527]\n",
      " [ 122.          170.14699527]\n",
      " [ 124.          170.14699527]\n",
      " [ 125.          170.14699527]\n",
      " [ 126.          170.14699527]\n",
      " [ 127.          170.14699527]\n",
      " [ 111.          170.14699527]\n",
      " [ 110.          170.14699527]\n",
      " [ 123.          170.14699527]\n",
      " [ 121.          170.14699527]]\n"
     ]
    }
   ],
   "source": [
    "# test - don't use\n",
    "\n",
    "# Image.fromarray(int_img1.astype(np.uint8)).show()\n",
    "print(np.shape(target_pca-source_pca[i]))\n",
    "print(np.sqrt(np.sum((target_pca-source_pca[i])**2, axis = 1)))\n",
    "print(rslt1)\n",
    "for i in range(10):\n",
    "    lt = Image.fromarray(cv2.imread(frames[i]))\n",
    "    b,g,r = lt.split()\n",
    "    lt = Image.merge(\"RGB\", (r, g, b))\n",
    "    lt.save(\"/home/shuvam/Downloads/facial-landmarks/rsltset/img\"+str(i)+\".jpg\")\n",
    "    lt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-15-5f6e61e9be66>, line 2)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-15-5f6e61e9be66>\"\u001b[0;36m, line \u001b[0;32m2\u001b[0m\n\u001b[0;31m    FFMPEG_BIN = \"ffmpeg\"\u001b[0m\n\u001b[0m             ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "# function to combine frames to generate video\n",
    "# incomplete\n",
    "\n",
    "img_names = \"img%0\"+(str(target_len)+\".jpg\"\n",
    "FFMPEG_BIN = \"ffmpeg\"\n",
    "command = [ FFMPEG_BIN,\n",
    "        '-y', # (optional) overwrite output file if it exists\n",
    "        '-f', 'rawvideo',\n",
    "        '-vcodec','rawvideo',\n",
    "        '-s', '256x256', # size of one frame\n",
    "        '-pix_fmt', 'rgb24',\n",
    "        '-r', '30', # frames per second\n",
    "        '-i', img_names, # The imput comes from a pipe\n",
    "        '-i', '/home/shuvam/Downloads/facial-landmarks/target/cut2.mp4',\n",
    "        '-map', '1:a:0',\n",
    "        '-shortest',\n",
    "        '-vcodec', 'mpeg'\",\n",
    "        'result.mp4' ]\n",
    "\n",
    "pipe = sp.Popen( command, stdin=sp.PIPE, stderr=sp.PIPE)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
