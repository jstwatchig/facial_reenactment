{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import the necessary packages\n",
    "\n",
    "from imutils.video import FileVideoStream\n",
    "from imutils import face_utils\n",
    "import datetime\n",
    "import argparse\n",
    "import imutils\n",
    "import math\n",
    "import time\n",
    "import dlib\n",
    "import cv2\n",
    "import numpy as np\n",
    "import sys\n",
    "import subprocess as sp\n",
    "from sklearn.decomposition import PCA\n",
    "from PIL import Image\n",
    "import csv\n",
    "from os import listdir\n",
    "from scipy.spatial.distance import pdist, squareform\n",
    "\n",
    "w = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load landmark detector\n",
    "\n",
    "print(\"[INFO] loading facial landmark predictor...\")\n",
    "detector = dlib.get_frontal_face_detector()\n",
    "predictor = dlib.shape_predictor('shape_predictor_68_face_landmarks.dat')\n",
    "fa = face_utils.FaceAligner(predictor, desiredFaceWidth=256)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to calculate weighted median per pixel\n",
    "\n",
    "def weighted_median(data, midpoint, weights=None):\n",
    "    import numpy as np\n",
    "    if weights is None:\n",
    "        return np.median(np.array(data).flatten())\n",
    "    data, weights = np.array(data).flatten(), np.array(weights).flatten()\n",
    "    if any(weights > 0):\n",
    "        sorted_data, sorted_weights = map(np.array, zip(*sorted(zip(data, weights))))\n",
    "        if any(weights > midpoint):\n",
    "            return (data[weights == np.max(weights)])[0]\n",
    "        cumulative_weight = np.cumsum(sorted_weights)\n",
    "        below_midpoint_index = np.where(cumulative_weight <= midpoint)[0][-1]\n",
    "        if cumulative_weight[below_midpoint_index] - midpoint < sys.float_info.epsilon:\n",
    "            return np.mean(sorted_data[below_midpoint_index:below_midpoint_index+2])\n",
    "    return sorted_data[below_midpoint_index+1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to calculate sigma\n",
    "\n",
    "def calcSigma(S_n, S_N, S_target, n, N):\n",
    "    left = 1\n",
    "    right = 1000\n",
    "    while left < right:\n",
    "        mid = int(left + (right - left) / 2)\n",
    "        start = np.sum(calcWeight(S_n, S_target, n, left/10)) - 0.9*np.sum(calcWeight(S_N, S_target, N, left/10))\n",
    "        end = np.sum(calcWeight(S_n, S_target, n, right/10)) - 0.9*np.sum(calcWeight(S_N, S_target, N, right/10))\n",
    "        if start > end:\n",
    "            right = mid\n",
    "        else:\n",
    "            left = mid+1\n",
    "    return left"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to calculate weight, given sigma (to be changed to include sigma)\n",
    "\n",
    "def calcWeight(S, S_target, len, sigma):\n",
    "    const = 2*(sigma**2)\n",
    "    global w \n",
    "    w = []\n",
    "    for i in range(len):\n",
    "        z = (np.linalg.norm(S[i] - S_target))**2\n",
    "        w = np.append(w, np.exp(-z/const))\n",
    "    return w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to mask the target image\n",
    "\n",
    "def maskFrames(imgs, centres, N):\n",
    "    new_imgs = []\n",
    "    centres = centres.astype(int)\n",
    "    for i in range(N):\n",
    "        img = cv2.imread(imgs[i])\n",
    "        v = Image.fromarray(img[(centres[i][1]-50):(centres[i][1]+50), (centres[i][0]-50):(centres[i][0]+50)])\n",
    "        b, g, r = v.split()\n",
    "        inter_img = Image.merge(\"RGB\", (r, g, b))\n",
    "        val = \"/home/shuvam/Downloads/facial-landmarks/internal/img\"+str(i)+\".jpg\"\n",
    "        inter_img.save(val)\n",
    "        new_imgs = np.append(new_imgs, val)\n",
    "    return new_imgs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to calculate weighted median for all target images\n",
    "\n",
    "def weightedMedian(S_all, S_target, target_frame, S_centres, S_centres_n, frames, target_centre, S_vec, S_vec_n, n, N, weights):\n",
    "    x_num = 100\n",
    "    y_num = 100\n",
    "    \n",
    "    weight_sum = 0.5*np.sum(weights)\n",
    "    centre_x = target_centre[0] - (y_num/2)\n",
    "    centre_y = target_centre[1] - (x_num/2)\n",
    "    masked_images_n = maskFrames(S_vec_n, S_centres_n, n)\n",
    "    im_res = np.zeros((x_num, y_num, 3))\n",
    "    S_target_new = cv2.imread(target_frame)\n",
    "    S_int = np.zeros((100, 100, 3))\n",
    "    \n",
    "    b = []\n",
    "    g = []\n",
    "    r = []\n",
    "    \n",
    "    t = 0\n",
    "    \n",
    "    b1 = []\n",
    "    g1 = []\n",
    "    r1 = []\n",
    "    \n",
    "    for x in range(n):\n",
    "        img = Image.open(masked_images_n[x])\n",
    "        B, G, R = img.split()\n",
    "        B = np.asarray(B)\n",
    "        G = np.asarray(G)\n",
    "        R = np.asarray(R)\n",
    "        if t == 0:\n",
    "            b = np.append(b, np.reshape(B, (np.product(B.shape),)))\n",
    "            g = np.append(g, np.reshape(G, (np.product(G.shape),)))\n",
    "            r = np.append(r, np.reshape(R, (np.product(R.shape),)))\n",
    "            t = 1\n",
    "        else:\n",
    "            b = np.vstack((b, np.reshape(B, (np.product(B.shape),))))\n",
    "            g = np.vstack((g, np.reshape(G, (np.product(G.shape),))))\n",
    "            r = np.vstack((r, np.reshape(R, (np.product(R.shape),))))\n",
    "            \n",
    "    for i in range (x_num*y_num):\n",
    "        b1 = np.append(b1, weighted_median(b[:,i], weight_sum, weights = w))\n",
    "        g1 = np.append(g1, weighted_median(g[:,i], weight_sum, weights = w))\n",
    "        r1 = np.append(r1, weighted_median(r[:,i], weight_sum, weights = w))\n",
    "    \n",
    "    t = 0\n",
    "    for i in range(x_num):\n",
    "        for j in range(y_num):\n",
    "            z = (r1[t], g1[t], b1[t])\n",
    "            S_target_new[int(centre_y+i)][int(centre_x+j)] = z\n",
    "            t += 1\n",
    "            \n",
    "    return S_target_new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate pca\n",
    "\n",
    "def find_PCA(video_link, folder):\n",
    "    vs = FileVideoStream(video_link).start()\n",
    "    time.sleep(2.0)\n",
    "    start_time = time.time()\n",
    "    \n",
    "    frameNo = 1\n",
    "    t = 0\n",
    "    imgs_rslt = []\n",
    "    centres = []\n",
    "    frame_list = []\n",
    "    length = int(cv2.VideoCapture(video_link).get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "\n",
    "    # loop over the frames from the video stream\n",
    "    while True:\n",
    "        \n",
    "        frame = vs.read()\n",
    "        frame = imutils.resize(frame, width=600)\n",
    "        gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "        rects = detector(gray, 0)\n",
    "        \n",
    "        # loop over the face detections\n",
    "        for rect in rects:\n",
    "            \n",
    "            faceAligned = fa.align(frame, gray, rect)\n",
    "            dirs = folder + str(frameNo) + \".jpg\"\n",
    "            cv2.imwrite(dirs, faceAligned)\n",
    "            rectan = dlib.rectangle(0, 0, 256, 256)\n",
    "            grays = cv2.cvtColor(faceAligned, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "            shape = predictor(grays, rectan)\n",
    "            shape = face_utils.shape_to_np(shape)\n",
    "            \n",
    "            shapes = np.concatenate([shape[48:61], shape[62:65]])\n",
    "            shapes = np.concatenate([shapes, shape[66:69]])\n",
    "            imgs = np.reshape(shapes, (np.product(shapes.shape),))\n",
    "            \n",
    "            if t == 0:\n",
    "                centres = np.append(centres, np.sum(shapes, axis=0))\n",
    "                imgs_rslt = np.append(imgs_rslt,imgs)\n",
    "                t = 1\n",
    "\n",
    "            else:\n",
    "                centres = np.vstack((centres, np.sum(shapes, axis=0)))\n",
    "                imgs_rslt = np.vstack((imgs_rslt,imgs))\n",
    "            \n",
    "            frame_list = np.append(frame_list, dirs)\n",
    "\n",
    "        # increment frame count\n",
    "        if frameNo < length:\n",
    "            frameNo += 1\n",
    "        else:\n",
    "            vs.stop()\n",
    "            break\n",
    "\n",
    "    imgs_rslt = imgs_rslt.astype(int)\n",
    "    centres = (centres/[18, 18]).astype(int)\n",
    "    \n",
    "    pca = PCA(n_components=20)\n",
    "    img_pca = pca.fit_transform(imgs_rslt)\n",
    "    \n",
    "    elapsed_time = time.time() - start_time\n",
    "    print(\"Done here...\")\n",
    "    print(\"Elapsed time - \" + str(elapsed_time))\n",
    "    \n",
    "    return imgs_rslt, img_pca, frame_list, length, centres"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate pca\n",
    "# modified image loading\n",
    "\n",
    "def find_PCA(folder):\n",
    "    time.sleep(2.0)\n",
    "    start_time = time.time()\n",
    "    \n",
    "    frameNo = 1\n",
    "    t = 0\n",
    "    imgs_rslt = []\n",
    "    centres = []\n",
    "    frame_list = []\n",
    "    imagesList = sorted(listdir(folder))\n",
    "    length = len(imagesList)\n",
    "\n",
    "    # loop over the frames from the video stream\n",
    "    for image in imagesList:\n",
    "        \n",
    "        frame = cv2.imread(folder + image)\n",
    "        frame = imutils.resize(frame, width=600)\n",
    "        gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "        rects = detector(gray, 0)\n",
    "        \n",
    "        # loop over the face detections\n",
    "        for rect in rects:\n",
    "            \n",
    "            faceAligned = fa.align(frame, gray, rect)\n",
    "            dirs = folder + image\n",
    "            rectan = dlib.rectangle(0, 0, 256, 256)\n",
    "            grays = cv2.cvtColor(faceAligned, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "            shape = predictor(grays, rectan)\n",
    "            shape = face_utils.shape_to_np(shape)\n",
    "            \n",
    "            shapes = np.concatenate([shape[48:61], shape[62:65]])\n",
    "            shapes = np.concatenate([shapes, shape[66:69]])\n",
    "            imgs = np.reshape(shapes, (np.product(shapes.shape),))\n",
    "            \n",
    "            if t == 0:\n",
    "                centres = np.append(centres, np.sum(shapes, axis=0))\n",
    "                imgs_rslt = np.append(imgs_rslt,imgs)\n",
    "                t = 1\n",
    "\n",
    "            else:\n",
    "                centres = np.vstack((centres, np.sum(shapes, axis=0)))\n",
    "                imgs_rslt = np.vstack((imgs_rslt,imgs))\n",
    "            \n",
    "            frame_list = np.append(frame_list, dirs)\n",
    "\n",
    "        # increment frame count\n",
    "        frameNo += 1\n",
    "\n",
    "    imgs_rslt = imgs_rslt.astype(int)\n",
    "    centres = (centres/[18, 18]).astype(int)\n",
    "    \n",
    "    pca = PCA(n_components=20)\n",
    "    img_pca = pca.fit_transform(imgs_rslt)\n",
    "    \n",
    "    elapsed_time = time.time() - start_time\n",
    "    print(\"Done here...\")\n",
    "    print(\"Elapsed time - \" + str(elapsed_time))\n",
    "    \n",
    "    return imgs_rslt, img_pca, frame_list, length, centres"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate l2 similarity\n",
    "\n",
    "def similarity(src_pca, tgt_pca, len):\n",
    "    dist = []\n",
    "    \n",
    "    for i in range(len-1):\n",
    "        if i == 0:\n",
    "            dist = np.append(dist, [i+1, np.linalg.norm(src_pca[i] - tgt_pca)])\n",
    "        else:\n",
    "            dist = np.vstack((dist, [i+1, np.linalg.norm(src_pca[i] - tgt_pca)]))\n",
    "\n",
    "    dist = dist[dist[:,1].argsort()]\n",
    "    return dist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done here...\n",
      "Done here...\n"
     ]
    }
   ],
   "source": [
    "# preprocessing\n",
    "\n",
    "source_vec, source_pca, source_frame, source_len, source_centre = find_PCA(\"/home/shuvam/Downloads/facial-landmarks/source/\")\n",
    "target_vec, target_pca, target_frame, target_len, target_centre = find_PCA(\"/home/shuvam/Downloads/facial-landmarks/target/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Working on frame 94\n",
      "done\n",
      "Working on frame 95\n",
      "done\n",
      "Working on frame 96\n",
      "done\n",
      "Working on frame 97\n",
      "done\n",
      "Working on frame 98\n",
      "done\n",
      "Working on frame 99\n",
      "done\n",
      "Working on frame 100\n",
      "done\n",
      "Working on frame 101\n",
      "done\n",
      "Working on frame 102\n",
      "done\n",
      "Working on frame 103\n",
      "done\n",
      "Working on frame 104\n",
      "done\n",
      "Working on frame 105\n",
      "done\n",
      "Working on frame 106\n",
      "done\n",
      "Working on frame 107\n",
      "done\n",
      "Working on frame 108\n",
      "done\n",
      "Working on frame 109\n",
      "done\n",
      "Working on frame 110\n",
      "done\n",
      "Working on frame 111\n",
      "done\n",
      "Working on frame 112\n",
      "done\n",
      "Working on frame 113\n",
      "done\n",
      "Working on frame 114\n",
      "done\n",
      "Working on frame 115\n",
      "done\n",
      "Working on frame 116\n",
      "done\n",
      "Working on frame 117\n",
      "done\n",
      "Working on frame 118\n",
      "done\n",
      "Working on frame 119\n",
      "done\n",
      "Working on frame 120\n",
      "done\n",
      "Working on frame 121\n",
      "done\n",
      "Working on frame 122\n",
      "done\n",
      "Working on frame 123\n",
      "done\n",
      "Working on frame 124\n",
      "done\n",
      "Working on frame 125\n",
      "done\n",
      "Working on frame 126\n",
      "done\n",
      "Working on frame 127\n",
      "done\n",
      "Working on frame 128\n",
      "done\n",
      "Working on frame 129\n",
      "done\n",
      "Working on frame 130\n",
      "done\n",
      "Working on frame 131\n",
      "done\n",
      "Working on frame 132\n",
      "done\n",
      "Working on frame 133\n",
      "done\n",
      "Working on frame 134\n",
      "done\n",
      "Working on frame 135\n",
      "done\n",
      "Working on frame 136\n",
      "done\n",
      "Working on frame 137\n",
      "done\n",
      "Working on frame 138\n",
      "done\n",
      "Working on frame 139\n",
      "done\n",
      "Working on frame 140\n",
      "done\n",
      "Working on frame 141\n",
      "done\n",
      "Working on frame 142\n",
      "done\n",
      "Working on frame 143\n",
      "done\n",
      "Working on frame 144\n",
      "done\n",
      "Working on frame 145\n",
      "done\n",
      "Working on frame 146\n",
      "done\n",
      "Working on frame 147\n",
      "done\n",
      "Working on frame 148\n",
      "done\n",
      "Working on frame 149\n",
      "done\n",
      "Working on frame 150\n",
      "done\n",
      "Working on frame 151\n",
      "done\n",
      "Working on frame 152\n",
      "done\n",
      "Working on frame 153\n",
      "done\n",
      "Working on frame 154\n",
      "done\n",
      "Working on frame 155\n",
      "done\n",
      "Working on frame 156\n",
      "done\n",
      "Working on frame 157\n",
      "done\n",
      "Working on frame 158\n",
      "done\n",
      "Working on frame 159\n",
      "done\n",
      "Working on frame 160\n",
      "done\n",
      "Working on frame 161\n",
      "done\n",
      "Working on frame 162\n",
      "done\n",
      "Working on frame 163\n",
      "done\n",
      "Working on frame 164\n",
      "done\n",
      "Working on frame 165\n",
      "done\n",
      "Working on frame 166\n",
      "done\n",
      "Working on frame 167\n",
      "done\n",
      "Working on frame 168\n",
      "done\n",
      "Working on frame 169\n",
      "done\n",
      "Working on frame 170\n",
      "done\n",
      "Working on frame 171\n",
      "done\n",
      "Working on frame 172\n",
      "done\n",
      "Working on frame 173\n",
      "done\n",
      "Working on frame 174\n",
      "done\n",
      "Working on frame 175\n",
      "done\n",
      "Working on frame 176\n",
      "done\n",
      "Working on frame 177\n",
      "done\n",
      "Working on frame 178\n",
      "done\n",
      "Working on frame 179\n",
      "done\n",
      "Working on frame 180\n",
      "done\n",
      "Working on frame 181\n",
      "done\n",
      "Working on frame 182\n",
      "done\n",
      "Working on frame 183\n",
      "done\n",
      "Working on frame 184\n",
      "done\n",
      "Working on frame 185\n",
      "done\n",
      "Working on frame 186\n",
      "done\n",
      "Working on frame 187\n",
      "done\n",
      "Working on frame 188\n",
      "done\n",
      "Working on frame 189\n",
      "done\n",
      "Working on frame 190\n",
      "done\n",
      "Working on frame 191\n",
      "done\n",
      "Working on frame 192\n",
      "done\n",
      "Working on frame 193\n",
      "done\n",
      "Working on frame 194\n",
      "done\n",
      "Working on frame 195\n",
      "done\n",
      "Working on frame 196\n",
      "done\n",
      "Working on frame 197\n",
      "done\n",
      "Working on frame 198\n",
      "done\n",
      "Working on frame 199\n",
      "done\n",
      "Working on frame 200\n",
      "done\n",
      "Working on frame 201\n",
      "done\n",
      "Working on frame 202\n",
      "done\n",
      "Working on frame 203\n",
      "done\n",
      "Working on frame 204\n",
      "done\n",
      "Working on frame 205\n",
      "done\n",
      "Working on frame 206\n",
      "done\n",
      "Working on frame 207\n",
      "done\n",
      "Working on frame 208\n",
      "done\n",
      "Working on frame 209\n",
      "done\n",
      "Working on frame 210\n",
      "done\n",
      "Working on frame 211\n",
      "done\n",
      "Working on frame 212\n",
      "done\n",
      "Working on frame 213\n",
      "done\n",
      "Working on frame 214\n",
      "done\n",
      "Working on frame 215\n",
      "done\n",
      "Working on frame 216\n",
      "done\n",
      "Working on frame 217\n",
      "done\n",
      "Working on frame 218\n",
      "done\n",
      "Working on frame 219\n",
      "done\n",
      "Working on frame 220\n"
     ]
    }
   ],
   "source": [
    "n = 40\n",
    "target_len = len(target_vec)\n",
    "source_len = len(source_vec)\n",
    "for i in range(94,4600):\n",
    "    start_time = time.time()\n",
    "    y = []\n",
    "    centres = []\n",
    "    rslt = similarity(target_vec, source_vec[i], target_len)\n",
    "    frames = []\n",
    "    rslt1 = rslt\n",
    "    rslt = rslt[:n]\n",
    "    t = 0\n",
    "    \n",
    "    for z in rslt[:,0].astype(int):\n",
    "        if t == 0:\n",
    "            y = np.append(y, target_vec[z-1])\n",
    "            centres = np.append(centres, target_centre[z-1])\n",
    "            frames = np.append(frames, target_frame[z-1])\n",
    "            t = 1\n",
    "        else:\n",
    "            y = np.vstack((y, target_vec[z-1]))\n",
    "            centres = np.vstack((centres, target_centre[z-1]))\n",
    "            frames = np.append(frames, target_frame[z-1])\n",
    "            \n",
    "    y = y.astype(int)\n",
    "    print(\"Working on frame \" + str(i))\n",
    "    sigma = calcSigma(y, target_vec, source_vec[i], n, target_len)\n",
    "    weight = calcWeight(y, target_vec[i], n, sigma)\n",
    "    gen_img = weightedMedian(source_vec, target_vec[i], target_frame[i], source_centre, centres, frames, target_centre[i], source_frame, frames, n, target_len, weight)\n",
    "    gen_img = Image.fromarray(gen_img)\n",
    "    b, g, r = gen_img.split()\n",
    "    gen_img = Image.merge(\"RGB\", (r, g, b))\n",
    "    gen_img.save(\"/home/shuvam/Downloads/facial-landmarks/inter/img\"+('0'*(len(str(target_len))-len(str(i))))+str(i)+\".jpg\")\n",
    "    elapsed_time = time.time() - start_time\n",
    "    print(\"Done\")\n",
    "    print(\"Elapsed time - \" + str(elapsed_time)+'\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 4473.            10.95445115]\n",
      " [ 3727.            13.07669683]\n",
      " [ 4409.            13.22875656]\n",
      " [ 4408.            14.03566885]\n",
      " [ 3720.            15.03329638]\n",
      " [ 3700.            15.06651917]\n",
      " [ 3726.            15.13274595]\n",
      " [ 3823.            15.13274595]\n",
      " [ 3830.            15.39480432]\n",
      " [ 3725.            15.49193338]\n",
      " [ 2703.            15.71623365]\n",
      " [ 4472.            15.8113883 ]\n",
      " [ 3701.            15.87450787]\n",
      " [ 3721.            16.0623784 ]\n",
      " [ 3931.            16.2788206 ]\n",
      " [ 3744.            16.2788206 ]\n",
      " [ 2701.            16.55294536]\n",
      " [ 3719.            16.64331698]\n",
      " [ 3724.            16.70329309]\n",
      " [ 2704.            16.73320053]\n",
      " [ 2700.            16.73320053]\n",
      " [ 3557.            16.76305461]\n",
      " [ 3738.            16.79285562]\n",
      " [ 4410.            16.82260384]\n",
      " [ 2702.            16.85229955]\n",
      " [ 3745.            16.91153453]\n",
      " [ 4412.            17.        ]\n",
      " [ 3829.            17.11724277]\n",
      " [ 4414.            17.20465053]\n",
      " [  415.            17.29161647]\n",
      " [ 3558.            17.40689519]\n",
      " [ 4415.            17.49285568]\n",
      " [ 4407.            17.52141547]\n",
      " [ 2698.            17.57839583]\n",
      " [ 3822.            17.66352173]\n",
      " [ 4406.            17.94435844]\n",
      " [ 4405.            17.94435844]\n",
      " [ 4411.            17.97220076]\n",
      " [ 3737.            18.08314132]\n",
      " [ 3722.            18.11077028]\n",
      " [ 3556.            18.11077028]\n",
      " [ 3572.            18.35755975]\n",
      " [ 3743.            18.38477631]\n",
      " [ 3824.            18.49324201]\n",
      " [ 2681.            18.54723699]\n",
      " [ 1256.            18.54723699]\n",
      " [ 4413.            18.60107524]\n",
      " [ 4474.            18.86796226]\n",
      " [ 3730.            18.92088793]\n",
      " [  238.            18.92088793]]\n",
      "left 0.0\n",
      "right -3705.03307557\n",
      "left 0.0\n",
      "right -2781.88294126\n",
      "left 0.0\n",
      "right -1021.38349646\n",
      "left 0.0\n",
      "right -52.6194420349\n",
      "left 0.0\n",
      "right -0.0415239090607\n",
      "left 0.0\n",
      "right 3.21606883688e-07\n",
      "left 2.09343014532e-21\n",
      "right 3.21606883688e-07\n",
      "left 1.0859777969e-10\n",
      "right 3.21606883688e-07\n",
      "left 2.25895981239e-08\n",
      "right 3.21606883688e-07\n",
      "left 1.46553747663e-07\n",
      "right 3.21606883688e-07\n",
      "32\n"
     ]
    }
   ],
   "source": [
    "# test cell 1 (don't run)\n",
    "\n",
    "n = 50\n",
    "target_len = len(target_vec)\n",
    "y = []\n",
    "rslt = similarity(target_vec, source_vec[108], target_len)\n",
    "rslt = rslt[:n]\n",
    "print(rslt)\n",
    "t = 0\n",
    "for z in rslt[:,0].astype(int):\n",
    "    if t == 0:\n",
    "        y = np.append(y, target_vec[z-1])\n",
    "        t = 1\n",
    "    else:\n",
    "        y = np.vstack((y, target_vec[z-1]))\n",
    "y = y.astype(int)\n",
    "sigma = calcSigma(y, target_vec, source_vec[107], n, target_len)\n",
    "print(sigma)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 4473.            10.95445115]\n",
      " [ 3727.            13.07669683]\n",
      " [ 4409.            13.22875656]\n",
      " [ 4408.            14.03566885]\n",
      " [ 3720.            15.03329638]\n",
      " [ 3700.            15.06651917]\n",
      " [ 3726.            15.13274595]\n",
      " [ 3823.            15.13274595]\n",
      " [ 3830.            15.39480432]\n",
      " [ 3725.            15.49193338]\n",
      " [ 2703.            15.71623365]\n",
      " [ 4472.            15.8113883 ]\n",
      " [ 3701.            15.87450787]\n",
      " [ 3721.            16.0623784 ]\n",
      " [ 3931.            16.2788206 ]\n",
      " [ 3744.            16.2788206 ]\n",
      " [ 2701.            16.55294536]\n",
      " [ 3719.            16.64331698]\n",
      " [ 3724.            16.70329309]\n",
      " [ 2704.            16.73320053]\n",
      " [ 2700.            16.73320053]\n",
      " [ 3557.            16.76305461]\n",
      " [ 3738.            16.79285562]\n",
      " [ 4410.            16.82260384]\n",
      " [ 2702.            16.85229955]\n",
      " [ 3745.            16.91153453]\n",
      " [ 4412.            17.        ]\n",
      " [ 3829.            17.11724277]\n",
      " [ 4414.            17.20465053]\n",
      " [  415.            17.29161647]\n",
      " [ 3558.            17.40689519]\n",
      " [ 4415.            17.49285568]\n",
      " [ 4407.            17.52141547]\n",
      " [ 2698.            17.57839583]\n",
      " [ 3822.            17.66352173]\n",
      " [ 4406.            17.94435844]\n",
      " [ 4405.            17.94435844]\n",
      " [ 4411.            17.97220076]\n",
      " [ 3737.            18.08314132]\n",
      " [ 3722.            18.11077028]\n",
      " [ 3556.            18.11077028]\n",
      " [ 3572.            18.35755975]\n",
      " [ 3743.            18.38477631]\n",
      " [ 3824.            18.49324201]\n",
      " [ 2681.            18.54723699]\n",
      " [ 1256.            18.54723699]\n",
      " [ 4413.            18.60107524]\n",
      " [ 4474.            18.86796226]\n",
      " [ 3730.            18.92088793]\n",
      " [  238.            18.92088793]]\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "6.78901869844e-232\n",
      "1.5194971397e-161\n",
      "4.13309636043e-119\n",
      "1.47950490749e-91\n",
      "1.17196423222e-72\n",
      "3.90866968709e-59\n",
      "3.98655907284e-49\n",
      "1.63975723408e-41\n",
      "1.38536072862e-35\n",
      "6.99894523525e-31\n",
      "4.36561424464e-27\n",
      "5.57574870067e-24\n",
      "2.09343014532e-21\n",
      "3.0084994488e-19\n",
      "2.01370718428e-17\n",
      "7.28071406993e-16\n",
      "1.59301758207e-14\n",
      "2.30381130224e-13\n",
      "2.36026544096e-12\n",
      "1.81002917356e-11\n",
      "1.0859777969e-10\n",
      "5.2834058659e-10\n",
      "2.14610636621e-09\n",
      "7.45505699575e-09\n",
      "2.25895981239e-08\n",
      "6.0692146152e-08\n",
      "1.46553747663e-07\n",
      "3.21606883688e-07\n",
      "6.47165825308e-07\n",
      "1.2025563862e-06\n",
      "2.07380417506e-06\n",
      "3.32814390847e-06\n",
      "4.96985903599e-06\n",
      "6.87369623168e-06\n",
      "8.69295055806e-06\n",
      "9.73981810753e-06\n",
      "8.83534053256e-06\n",
      "4.12495228427e-06\n",
      "-7.1467656202e-06\n",
      "-2.89118553386e-05\n",
      "-6.66189229261e-05\n",
      "-0.000127654946111\n",
      "-0.000221870337311\n",
      "-0.000362231528915\n",
      "-0.000565627037934\n",
      "-0.000853853206513\n",
      "-0.00125480447035\n",
      "-0.00180389007505\n",
      "-0.00254569475544\n",
      "-0.00353589522955\n",
      "-0.00484343772633\n",
      "-0.0065529745013\n",
      "-0.00876754975488\n",
      "-0.0116115179044\n",
      "-0.0152336700982\n",
      "-0.0198105384733\n",
      "-0.0255498421749\n",
      "-0.0326940347256\n",
      "-0.0415239090607\n",
      "-0.0523622144582\n",
      "-0.0655772386788\n",
      "-0.0815863088254\n",
      "-0.100859165641\n",
      "-0.123921168066\n",
      "-0.151356287745\n",
      "-0.183809856643\n",
      "-0.221991034925\n",
      "-0.266674970526\n",
      "-0.318704626393\n",
      "-0.378992256014\n",
      "-0.448520512467\n",
      "-0.528343180817\n",
      "-0.619585528038\n",
      "-0.723444268868\n",
      "-0.841187149894\n",
      "-0.974152157795\n",
      "-1.12374636095\n",
      "-1.2914443966\n",
      "-1.47878661823\n",
      "-1.68737692035\n",
      "-1.91888025936\n",
      "-2.17501989109\n",
      "-2.45757434672\n",
      "-2.76837416955\n",
      "-3.10929843609\n",
      "-3.48227108496\n",
      "-3.88925707752\n",
      "-4.33225841382\n",
      "-4.8133100275\n",
      "-5.33447558257\n",
      "-5.8978431945\n",
      "-6.50552109745\n",
      "-7.1596332786\n",
      "-7.86231509947\n",
      "-8.61570892355\n",
      "-9.42195976808\n",
      "-10.2832109971\n",
      "-11.2016000718\n",
      "-12.1792543725\n",
      "-13.2182871069\n",
      "-14.320793316\n",
      "-15.4888459901\n",
      "-16.724492305\n",
      "-18.0297499876\n",
      "-19.4066038193\n",
      "-20.8570022846\n",
      "-22.3828543713\n",
      "-23.9860265268\n",
      "-25.6683397763\n",
      "-27.4315670056\n",
      "-29.2774304115\n",
      "-31.2075991212\n",
      "-33.2236869834\n",
      "-35.3272505295\n",
      "-37.5197871068\n",
      "-39.8027331814\n",
      "-42.1774628101\n",
      "-44.6452862791\n",
      "-47.2074489079\n",
      "-49.8651300136\n",
      "-52.6194420349\n",
      "-55.4714298098\n",
      "-58.4220700046\n",
      "-61.4722706885\n",
      "-64.6228710508\n",
      "-67.874641254\n",
      "-71.2282824194\n",
      "-74.6844267393\n",
      "-78.2436377099\n",
      "-81.9064104804\n",
      "-85.6731723125\n",
      "-89.5442831443\n",
      "-93.5200362529\n",
      "-97.600659011\n",
      "-101.786313731\n",
      "-106.07709859\n",
      "-110.473048636\n",
      "-114.974136856\n",
      "-119.580275322\n",
      "-124.291316384\n",
      "-129.107053931\n",
      "-134.027224696\n",
      "-139.051509601\n",
      "-144.179535154\n",
      "-149.410874874\n",
      "-154.745050746\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-110-2dc3b6b83012>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     13\u001b[0m         \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvstack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_vec\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mz\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m \u001b[0msigma\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcalcSigma\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_vec\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msource_vec\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m107\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_len\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msigma\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-109-b9e520b790bb>\u001b[0m in \u001b[0;36mcalcSigma\u001b[0;34m(S_n, S_N, S_target, n, N)\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1000\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m         \u001b[0;31m# print(\"for i=\"+str(i/10))\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m         \u001b[0mx2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcalcWeight\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mS_N\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mS_target\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mN\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m         \u001b[0mx1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcalcWeight\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mS_n\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mS_target\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m         \u001b[0mtemp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx1\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m0.9\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mx2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-68-69cf68cf5d0f>\u001b[0m in \u001b[0;36mcalcWeight\u001b[0;34m(S, S_target, len, sigma)\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0mw\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m         \u001b[0mz\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinalg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnorm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mS\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mS_target\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m         \u001b[0mw\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mw\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mz\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mconst\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mw\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/numpy/linalg/linalg.py\u001b[0m in \u001b[0;36mnorm\u001b[0;34m(x, ord, axis, keepdims)\u001b[0m\n\u001b[1;32m   2166\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2167\u001b[0m                 \u001b[0msqnorm\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2168\u001b[0;31m             \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msqrt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msqnorm\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2169\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mkeepdims\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2170\u001b[0m                 \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mret\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mndim\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# test cell 2 (don't run)\n",
    "\n",
    "n = 50\n",
    "target_len = len(target_vec)\n",
    "y = []\n",
    "rslt = similarity(target_vec, source_vec[108], target_len)\n",
    "rslt = rslt[:n]\n",
    "print(rslt)\n",
    "t = 0\n",
    "for z in rslt[:,0].astype(int):\n",
    "    if t == 0:\n",
    "        y = np.append(y, target_vec[z-1])\n",
    "        t = 1\n",
    "    else:\n",
    "        y = np.vstack((y, target_vec[z-1]))\n",
    "y = y.astype(int)\n",
    "sigma = calcSigma(y, target_vec, source_vec[107], n, target_len)\n",
    "print(sigma)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-15-5f6e61e9be66>, line 2)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-15-5f6e61e9be66>\"\u001b[0;36m, line \u001b[0;32m2\u001b[0m\n\u001b[0;31m    FFMPEG_BIN = \"ffmpeg\"\u001b[0m\n\u001b[0m             ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "# TODO\n",
    "# stitch images into video\n",
    "\n",
    "img_names = \"img%0\"+(str(target_len)+\".jpg\"\n",
    "FFMPEG_BIN = \"ffmpeg\"\n",
    "command = [ FFMPEG_BIN,\n",
    "        '-y', # (optional) overwrite output file if it exists\n",
    "        '-f', 'rawvideo',\n",
    "        '-vcodec','rawvideo',\n",
    "        '-s', '256x256', # size of one frame\n",
    "        '-pix_fmt', 'rgb24',\n",
    "        '-r', '30', # frames per second\n",
    "        '-i', img_names, # The imput comes from a pipe\n",
    "        '-i', '/home/shuvam/Downloads/facial-landmarks/target/cut2.mp4',\n",
    "        '-map', '1:a:0',\n",
    "        '-shortest',\n",
    "        '-vcodec', 'mpeg'\",\n",
    "        'result.mp4' ]\n",
    "\n",
    "pipe = sp.Popen( command, stdin=sp.PIPE, stderr=sp.PIPE)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
